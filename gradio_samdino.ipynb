{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gradio as gr\n",
    "from hf_samdino import process_video"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gradio_process_video(video_file, detector, \n",
    "                         box_threshold_1, box_threshold_2, \n",
    "                         text_threshold_1, text_threshold_2, \n",
    "                         confidence_1, confidence_2, \n",
    "                         iou_1, iou_2, \n",
    "                         frame_len, frame_stride, gif_duration):\n",
    "    box_threshold = [box_threshold_1, box_threshold_2]\n",
    "    text_threshold = [text_threshold_1, text_threshold_2]\n",
    "    yolo_confidence = [confidence_1, confidence_2]\n",
    "    yolo_iou_threhold = [iou_1, iou_2]\n",
    "    return process_video(video_path=video_file,\n",
    "                        detector=detector,\n",
    "                        dino_box_threshold=box_threshold,\n",
    "                        dino_text_threshold=text_threshold,\n",
    "                        yolo_confidence=yolo_confidence,\n",
    "                        yolo_iou_threshold=yolo_iou_threhold,\n",
    "                        frame_len=frame_len,\n",
    "                        frame_stride=frame_stride,\n",
    "                        gif_duration=gif_duration)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_inputs(detector):\n",
    "    if detector == \"Grounding DINO\":\n",
    "        # Show DINO sliders, hide YOLO sliders\n",
    "        return [gr.update(visible=True), gr.update(visible=False)]\n",
    "    else:\n",
    "        # Show YOLO sliders, hide DINO sliders\n",
    "        return [gr.update(visible=False), gr.update(visible=True)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Running on local URL:  http://127.0.0.1:7865\n",
      "* Running on public URL: https://96edfa21b3a14599fa.gradio.live\n",
      "\n",
      "This share link expires in 72 hours. For free permanent hosting and GPU upgrades, run `gradio deploy` from the terminal in the working directory to deploy to Hugging Face Spaces (https://huggingface.co/spaces)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"https://96edfa21b3a14599fa.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converting video to video frames\n",
      "Extracted 648 frames to 'output_video_frames'.\n",
      "using device: cuda\n",
      "Object detection of starting frame using YOLO\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "UserWarning: Specified provider 'CUDAExecutionProvider' is not in available provider names.Available providers: 'AzureExecutionProvider, CPUExecutionProvider'\n",
      "UserWarning: Specified provider 'OpenVINOExecutionProvider' is not in available provider names.Available providers: 'AzureExecutionProvider, CPUExecutionProvider'\n",
      "UserWarning: Specified provider 'CoreMLExecutionProvider' is not in available provider names.Available providers: 'AzureExecutionProvider, CPUExecutionProvider'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Frame  0\n",
      "Frame  1\n",
      "Frame  2\n",
      "Frame  3\n",
      "Frame  4\n",
      "Frame  5\n",
      "Frame  6\n",
      "Frame  7\n",
      "Frame  8\n",
      "Frame  9\n",
      "Frame  10\n",
      "Frame  11\n",
      "Frame  12\n",
      "Frame  13\n",
      "Frame  14\n",
      "Frame  15\n",
      "Frame  16\n",
      "Frame  17\n",
      "Frame  18\n",
      "Frame  19\n",
      "Frame  20\n",
      "Frame  21\n",
      "Frame  22\n",
      "Frame  23\n",
      "Frame  24\n",
      "Frame  25\n",
      "Frame  26\n",
      "Frame  27\n",
      "Frame  28\n",
      "Frame  29\n",
      "Frame  30\n",
      "Frame  31\n",
      "Frame  32\n",
      "Frame  33\n",
      "Frame  34\n",
      "Frame  35\n",
      "Frame  36\n",
      "Frame  37\n",
      "Frame  38\n",
      "Frame  39\n",
      "Frame  40\n",
      "Frame  41\n",
      "Frame  42\n",
      "Frame  43\n",
      "Frame  44\n",
      "Frame  45\n",
      "Frame  46\n",
      "Frame  47\n",
      "Frame  48\n",
      "Frame  49\n",
      "Frame  50\n",
      "Frame  51\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "UserWarning: FigureCanvasAgg is non-interactive, and thus cannot be shown\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading SAM2\n",
      "Initializing SAM2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "propagate in video:   0%|          | 0/100 [00:00<?, ?it/s]UserWarning: Memory efficient kernel not used because: (Triggered internally at C:\\cb\\pytorch_1000000000000\\work\\aten\\src\\ATen\\native\\transformers\\cuda\\sdp_utils.cpp:773.)\n",
      "UserWarning: Memory Efficient attention has been runtime disabled. (Triggered internally at C:\\cb\\pytorch_1000000000000\\work\\aten\\src\\ATen/native/transformers/sdp_utils_cpp.h:558.)\n",
      "UserWarning: Flash attention kernel not used because: (Triggered internally at C:\\cb\\pytorch_1000000000000\\work\\aten\\src\\ATen\\native\\transformers\\cuda\\sdp_utils.cpp:775.)\n",
      "UserWarning: Torch was not compiled with flash attention. (Triggered internally at C:\\cb\\pytorch_1000000000000\\work\\aten\\src\\ATen\\native\\transformers\\cuda\\sdp_utils.cpp:599.)\n",
      "UserWarning: CuDNN attention kernel not used because: (Triggered internally at C:\\cb\\pytorch_1000000000000\\work\\aten\\src\\ATen\\native\\transformers\\cuda\\sdp_utils.cpp:777.)\n",
      "UserWarning: head_dim should be no more than 128 (Triggered internally at C:\\cb\\pytorch_1000000000000\\work\\aten\\src\\ATen\\native\\transformers\\cuda\\sdp_utils.cpp:381.)\n",
      "UserWarning: Flash Attention kernel failed due to: No available kernel. Aborting execution.\n",
      "Falling back to all available kernels for scaled_dot_product_attention (which may have a slower speed).\n",
      "propagate in video: 100%|██████████| 100/100 [01:01<00:00,  1.62it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving annotations\n",
      "Saving segmented frames\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [00:45<00:00,  2.19it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating video and gif\n",
      "Video saved to output\\output.mp4\n"
     ]
    }
   ],
   "source": [
    "with gr.Blocks() as demo:\n",
    "    with gr.Row():\n",
    "        with gr.Column(scale=1):  # Left half for inputs\n",
    "            video = gr.Video(label=\"Upload Video\")\n",
    "            detector = gr.Radio(choices=[\"Grounding DINO\", \"YOLO\"], label=\"Choose a detector\")\n",
    "\n",
    "            with gr.Group(visible=False) as dino_sliders:\n",
    "                box_threshold_1 = gr.Slider(0, 1, value=0.35, step=0.05, label=\"Box Threshold (DINO): Player/Referee\")\n",
    "                box_threshold_2 = gr.Slider(0, 1, value=0.35, step=0.05, label=\"Box Threshold (DINO): Basketball\")\n",
    "                text_threshold_1 = gr.Slider(0, 1, value=0.35, step=0.05, label=\"Text Threshold (DINO): Player/Referee\")\n",
    "                text_threshold_2 = gr.Slider(0, 1, value=0.35, step=0.05, label=\"Text Threshold (DINO): Basketball\")\n",
    "\n",
    "            with gr.Group(visible=False) as yolo_sliders:\n",
    "                confidence_1 = gr.Slider(0, 1, value=0.3, step=0.05, label=\"Confidence (YOLO): Player/Referee\")\n",
    "                confidence_2 = gr.Slider(0, 1, value=0.75, step=0.05, label=\"Confidence (YOLO): Basketball\")\n",
    "                iou_1 = gr.Slider(0, 1, value=0.7, step=0.05, label=\"IOU Threshold (YOLO): Player/Referee\")\n",
    "                iou_2 = gr.Slider(0, 1, value=0.5, step=0.05, label=\"IOU Threshold (YOLO): Basketball\")\n",
    "\n",
    "            frame_len = gr.Slider(1, 500, value=100, step=1, label=\"Frame Length\")\n",
    "            frame_stride = gr.Slider(1, 50, value=3, step=1, label=\"Frame Stride\")\n",
    "            gif_duration = gr.Slider(1, 500, value=100, step=1, label=\"GIF Duration\")\n",
    "\n",
    "            submit = gr.Button(\"Process\")\n",
    "        \n",
    "        with gr.Column(scale=1):  # Right half for outputs\n",
    "            output = gr.Image(type=\"filepath\", label=\"Output\")\n",
    "\n",
    "    # Adjust outputs: first dino_sliders group, then yolo_sliders group\n",
    "    detector.change(\n",
    "        update_inputs,\n",
    "        inputs=[detector],\n",
    "        outputs=[dino_sliders, yolo_sliders]\n",
    "    )\n",
    "\n",
    "    # Submit button action\n",
    "    submit.click(\n",
    "        gradio_process_video,\n",
    "        inputs=[video, detector, box_threshold_1, box_threshold_2,\n",
    "                text_threshold_1, text_threshold_2,\n",
    "                confidence_1, confidence_2, iou_1, iou_2,\n",
    "                frame_len, frame_stride, gif_duration],\n",
    "        outputs=output\n",
    "    )\n",
    "\n",
    "demo.launch(share=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cis581_samdino",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
