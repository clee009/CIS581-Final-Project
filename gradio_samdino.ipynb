{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">[12/07/24 11:14:25] </span><span style=\"color: #800000; text-decoration-color: #800000\">WARNING </span> Your inference package version <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.29</span>.<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span> is out of date! Please upgrade to <a href=\"file://c:\\Users\\chris\\anaconda3\\envs\\cis581_samdino\\Lib\\site-packages\\inference\\core\\__init__.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">__init__.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file://c:\\Users\\chris\\anaconda3\\envs\\cis581_samdino\\Lib\\site-packages\\inference\\core\\__init__.py#41\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">41</span></a>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span>         version <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.29</span>.<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2</span> of inference for the latest features and bug fixes by    <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">              </span>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span>         running `pip install --upgrade inference`.                              <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">              </span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m[12/07/24 11:14:25]\u001b[0m\u001b[2;36m \u001b[0m\u001b[31mWARNING \u001b[0m Your inference package version \u001b[1;36m0.29\u001b[0m.\u001b[1;36m1\u001b[0m is out of date! Please upgrade to \u001b]8;id=182179;file://c:\\Users\\chris\\anaconda3\\envs\\cis581_samdino\\Lib\\site-packages\\inference\\core\\__init__.py\u001b\\\u001b[2m__init__.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=544349;file://c:\\Users\\chris\\anaconda3\\envs\\cis581_samdino\\Lib\\site-packages\\inference\\core\\__init__.py#41\u001b\\\u001b[2m41\u001b[0m\u001b]8;;\u001b\\\n",
       "\u001b[2;36m                    \u001b[0m         version \u001b[1;36m0.29\u001b[0m.\u001b[1;36m2\u001b[0m of inference for the latest features and bug fixes by    \u001b[2m              \u001b[0m\n",
       "\u001b[2;36m                    \u001b[0m         running `pip install --upgrade inference`.                              \u001b[2m              \u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import gradio as gr\n",
    "from hf_samdino import process_video\n",
    "from zoom import zoom_save_gif"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to process the input list\n",
    "def process_list(input_text):\n",
    "    # Split input by commas and strip whitespace\n",
    "    string_list = [item.strip() for item in input_text.split(\",\") if item.strip()]\n",
    "    return string_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gradio_process_video(video_file, detector, \n",
    "                         box_threshold_1, box_threshold_2, \n",
    "                         text_threshold_1, text_threshold_2, \n",
    "                         confidence_1, confidence_2, \n",
    "                         iou_1, iou_2, \n",
    "                         frame_len, frame_stride, gif_duration,\n",
    "                         use_prior_data, use_pose, out_file, fps, \n",
    "                         selected_ids, selected_labels, nearest_to_ball,\n",
    "                         x_padding, y_padding, x_interp, y_interp, zoom_interp):\n",
    "    box_threshold = [box_threshold_1, box_threshold_2]\n",
    "    text_threshold = [text_threshold_1, text_threshold_2]\n",
    "    yolo_confidence = [confidence_1, confidence_2]\n",
    "    yolo_iou_threhold = [iou_1, iou_2]\n",
    "\n",
    "    if not use_prior_data:\n",
    "        process_video(video_path=video_file,\n",
    "                    detector=detector,\n",
    "                    dino_box_threshold=box_threshold,\n",
    "                    dino_text_threshold=text_threshold,\n",
    "                    yolo_confidence=yolo_confidence,\n",
    "                    yolo_iou_threshold=yolo_iou_threhold,\n",
    "                    frame_len=frame_len,\n",
    "                    frame_stride=frame_stride,\n",
    "                    gif_duration=gif_duration)\n",
    "        \n",
    "    if use_pose and not use_prior_data:\n",
    "        # TODO: ZiYan's pose part\n",
    "        ...\n",
    "\n",
    "    selected_ids = process_list(selected_ids)\n",
    "    selected_labels = process_list(selected_labels)\n",
    "    \n",
    "    return zoom_save_gif(out_file, use_pose, fps, selected_ids, selected_labels, nearest_to_ball,\n",
    "                         x_padding, y_padding, x_interp, y_interp, zoom_interp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_inputs(detector):\n",
    "    if detector == \"Grounding DINO\":\n",
    "        # Show DINO sliders, hide YOLO sliders\n",
    "        return [gr.update(visible=True), gr.update(visible=False)]\n",
    "    else:\n",
    "        # Show YOLO sliders, hide DINO sliders\n",
    "        return [gr.update(visible=False), gr.update(visible=True)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Running on local URL:  http://127.0.0.1:7862\n",
      "* Running on public URL: https://6fe33ba2691e01a3ff.gradio.live\n",
      "\n",
      "This share link expires in 72 hours. For free permanent hosting and GPU upgrades, run `gradio deploy` from the terminal in the working directory to deploy to Hugging Face Spaces (https://huggingface.co/spaces)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"https://6fe33ba2691e01a3ff.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converting video to video frames\n",
      "Extracted 648 frames to 'output_video_frames'.\n",
      "using device: cuda\n",
      "Object detection of starting frame using YOLO\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "UserWarning: Specified provider 'CUDAExecutionProvider' is not in available provider names.Available providers: 'AzureExecutionProvider, CPUExecutionProvider'\n",
      "UserWarning: Specified provider 'OpenVINOExecutionProvider' is not in available provider names.Available providers: 'AzureExecutionProvider, CPUExecutionProvider'\n",
      "UserWarning: Specified provider 'CoreMLExecutionProvider' is not in available provider names.Available providers: 'AzureExecutionProvider, CPUExecutionProvider'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Frame  0\n",
      "Frame  1\n",
      "Frame  2\n",
      "Frame  3\n",
      "Frame  4\n",
      "Frame  5\n",
      "Frame  6\n",
      "Frame  7\n",
      "Frame  8\n",
      "Frame  9\n",
      "Frame  10\n",
      "Frame  11\n",
      "Frame  12\n",
      "Frame  13\n",
      "Frame  14\n",
      "Frame  15\n",
      "Frame  16\n",
      "Frame  17\n",
      "Frame  18\n",
      "Frame  19\n",
      "Frame  20\n",
      "Frame  21\n",
      "Frame  22\n",
      "Frame  23\n",
      "Frame  24\n",
      "Frame  25\n",
      "Frame  26\n",
      "Frame  27\n",
      "Frame  28\n",
      "Frame  29\n",
      "Frame  30\n",
      "Frame  31\n",
      "Frame  32\n",
      "Frame  33\n",
      "Frame  34\n",
      "Frame  35\n",
      "Frame  36\n",
      "Frame  37\n",
      "Frame  38\n",
      "Frame  39\n",
      "Frame  40\n",
      "Frame  41\n",
      "Frame  42\n",
      "Frame  43\n",
      "Frame  44\n",
      "Frame  45\n",
      "Frame  46\n",
      "Frame  47\n",
      "Frame  48\n",
      "Frame  49\n",
      "Frame  50\n",
      "Frame  51\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "UserWarning: FigureCanvasAgg is non-interactive, and thus cannot be shown\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading SAM2\n",
      "Initializing SAM2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "propagate in video: 100%|██████████| 100/100 [00:59<00:00,  1.67it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving annotations\n",
      "Converting video to video frames\n",
      "Extracted 1817 frames to 'output_video_frames'.\n",
      "using device: cuda\n",
      "Object detection of starting frame using YOLO\n",
      "Frame  0\n",
      "Loading SAM2\n",
      "Initializing SAM2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "propagate in video: 100%|██████████| 100/100 [01:10<00:00,  1.41it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving annotations\n"
     ]
    }
   ],
   "source": [
    "with gr.Blocks(title=\"Autozoom Basketball Game\") as demo:\n",
    "    with gr.Row():\n",
    "        with gr.Column(scale=1):  # Left half for inputs\n",
    "            video_file = gr.Video(label=\"Upload Video\")\n",
    "            detector = gr.Radio(choices=[\"Grounding DINO\", \"YOLO\"], label=\"Choose a detector\")\n",
    "\n",
    "            with gr.Group(visible=False) as dino_sliders:\n",
    "                box_threshold_1 = gr.Slider(0, 1, value=0.35, step=0.05, label=\"Box Threshold (DINO): Player/Referee\")\n",
    "                box_threshold_2 = gr.Slider(0, 1, value=0.35, step=0.05, label=\"Box Threshold (DINO): Basketball\")\n",
    "                text_threshold_1 = gr.Slider(0, 1, value=0.35, step=0.05, label=\"Text Threshold (DINO): Player/Referee\")\n",
    "                text_threshold_2 = gr.Slider(0, 1, value=0.35, step=0.05, label=\"Text Threshold (DINO): Basketball\")\n",
    "\n",
    "            with gr.Group(visible=False) as yolo_sliders:\n",
    "                confidence_1 = gr.Slider(0, 1, value=0.3, step=0.05, label=\"Confidence (YOLO): Player/Referee\")\n",
    "                confidence_2 = gr.Slider(0, 1, value=0.75, step=0.05, label=\"Confidence (YOLO): Basketball\")\n",
    "                iou_1 = gr.Slider(0, 1, value=0.7, step=0.05, label=\"IOU Threshold (YOLO): Player/Referee\")\n",
    "                iou_2 = gr.Slider(0, 1, value=0.5, step=0.05, label=\"IOU Threshold (YOLO): Basketball\")\n",
    "\n",
    "            frame_len = gr.Slider(1, 500, value=100, step=1, label=\"Frame Length\")\n",
    "            frame_stride = gr.Slider(1, 50, value=3, step=1, label=\"Frame Stride\")\n",
    "            gif_duration = gr.Slider(1, 500, value=100, step=1, label=\"GIF Duration\")\n",
    "            use_prior_data = gr.Checkbox(label=\"Use Previous Data\")\n",
    "            use_pose = gr.Checkbox(label=\"Use Pose Data\")\n",
    "            out_file = gr.Textbox(value=\"zoomed.gif\", placeholder=\"Out Filename\")\n",
    "            fps = gr.Slider(1, 60, value=12, step=1, label=\"FPS\")\n",
    "            selected_ids = gr.Textbox(placeholder=\"IDs Targeted (seperated by commas)\")\n",
    "            selected_labels = gr.Textbox(value=\"basketball\", placeholder=\"Labels Targeted (seperated by commas)\")\n",
    "            nearest_to_ball = gr.Slider(0, 10, value=3, step=1, label=\"Closest to Ball\")\n",
    "            x_padding = gr.Slider(1, 100, value=20, step=1, label=\"X Padding\")\n",
    "            y_padding = gr.Slider(1, 100, value=20, step=1, label=\"Y Padding\")\n",
    "            x_interp = gr.Slider(0, 1, value=0.5, step=0.05, label=\"X Interpolation\")\n",
    "            y_interp = gr.Slider(0, 1, value=0.5, step=0.05, label=\"Y Interpolation\")\n",
    "            zoom_interp = gr.Slider(0, 1, value=0.5, step=0.05, label=\"Zoom Interpolation\")\n",
    "\n",
    "            submit = gr.Button(\"Process\")\n",
    "        \n",
    "        with gr.Column(scale=1):  # Right half for outputs\n",
    "            output = gr.Image(type=\"filepath\", label=\"Output\")\n",
    "\n",
    "    # Adjust outputs: first dino_sliders group, then yolo_sliders group\n",
    "    detector.change(\n",
    "        update_inputs,\n",
    "        inputs=[detector],\n",
    "        outputs=[dino_sliders, yolo_sliders]\n",
    "    )\n",
    "\n",
    "    # Submit button action\n",
    "    submit.click(\n",
    "        gradio_process_video,\n",
    "        inputs=[video_file, detector, \n",
    "                box_threshold_1, box_threshold_2, \n",
    "                text_threshold_1, text_threshold_2, \n",
    "                confidence_1, confidence_2, \n",
    "                iou_1, iou_2, \n",
    "                frame_len, frame_stride, gif_duration,\n",
    "                use_prior_data, use_pose, out_file, fps, \n",
    "                selected_ids, selected_labels, nearest_to_ball,\n",
    "                x_padding, y_padding, x_interp, y_interp, zoom_interp],\n",
    "        outputs=output\n",
    "    )\n",
    "\n",
    "demo.launch(share=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cis581_samdino",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
